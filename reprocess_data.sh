#!/bin/bash
# é‡æ–°é¢„å¤„ç†æ•°æ®è„šæœ¬
# åˆ é™¤æ—§çš„ä¸å‡åŒ€æ•°æ®ï¼Œç”Ÿæˆæ–°çš„å‡åŒ€å¤§å°çš„ shard æ–‡ä»¶

DATA_DIR="/gpfs/hybrid/data/downloads/gcloud/arc-scbasecount/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens"
PARQUET_DIR="${DATA_DIR}/.parquet"

echo "=========================================="
echo "é‡æ–°é¢„å¤„ç†å•ç»†èƒæ•°æ®"
echo "=========================================="
echo ""

# æ˜¾ç¤ºæ—§æ•°æ®å¤§å°
echo "ğŸ“Š å½“å‰æ•°æ®å¤§å°ï¼š"
du -sh ${PARQUET_DIR}/*_shards 2>/dev/null || echo "æ²¡æœ‰æ‰¾åˆ°æ—§æ•°æ®"
echo ""

# è¯¢é—®ç¡®è®¤
read -p "âš ï¸  ç¡®è®¤åˆ é™¤ä»¥ä¸Šç›®å½•å¹¶é‡æ–°å¤„ç†æ•°æ®ï¼Ÿ[y/N] " -n 1 -r
echo ""
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "å·²å–æ¶ˆ"
    exit 0
fi

echo ""
echo "ğŸ—‘ï¸  åˆ é™¤æ—§æ•°æ®..."
rm -rf ${PARQUET_DIR}/train_shards
rm -rf ${PARQUET_DIR}/val_shards
rm -rf ${PARQUET_DIR}/test_shards
rm -rf ${PARQUET_DIR}/ood_shards
rm -rf ${PARQUET_DIR}/temp_chunks

echo "âœ“ æ—§æ•°æ®å·²åˆ é™¤"
echo ""

# é‡æ–°è¿è¡Œé¢„å¤„ç†
echo "ğŸ”„ å¼€å§‹é‡æ–°é¢„å¤„ç†..."
echo "å‚æ•°è¯´æ˜ï¼š"
echo "  - shard_size: 8000 (æ¯ä¸ªæ–‡ä»¶ 8000 ä¸ªæ ·æœ¬)"
echo "  - num_workers: 64 (å¹¶è¡Œå¤„ç†)"
echo "  - format: parquet"
echo ""

python preprocess_ae.py \
    --csv_path "data_info/ae_data_info.csv" \
    --vocab_path "data_info/gene_order.tsv" \
    --output_dir "${PARQUET_DIR}" \
    --min_genes 200 \
    --num_workers 64 \
    --shard_size 8000 \
    --format "parquet"

EXIT_CODE=$?

echo ""
if [ $EXIT_CODE -eq 0 ]; then
    echo "âœ… é¢„å¤„ç†å®Œæˆï¼"
    echo ""
    echo "ğŸ“Š æ–°æ•°æ®ç»Ÿè®¡ï¼š"
    for split in train val test ood; do
        shard_dir="${PARQUET_DIR}/${split}_shards"
        if [ -d "$shard_dir" ]; then
            num_files=$(ls -1 ${shard_dir}/*.parquet 2>/dev/null | wc -l)
            total_size=$(du -sh ${shard_dir} | cut -f1)
            echo "  ${split}: ${num_files} ä¸ªæ–‡ä»¶, æ€»å¤§å° ${total_size}"
        fi
    done
    echo ""
    echo "éªŒè¯æ–‡ä»¶å¤§å°å‡åŒ€æ€§..."
    python3 << 'EOF'
import pyarrow.parquet as pq
from pathlib import Path
import statistics

parquet_dir = Path("/gpfs/hybrid/data/downloads/gcloud/arc-scbasecount/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/.parquet")
train_files = list((parquet_dir / "train_shards").glob("*.parquet"))

if train_files:
    # é‡‡æ ·æ£€æŸ¥
    sample_files = train_files[:50]
    sizes = []
    for f in sample_files:
        meta = pq.read_metadata(f)
        sizes.append(meta.num_rows)

    print(f"  é‡‡æ · {len(sample_files)} ä¸ªæ–‡ä»¶:")
    print(f"    æœ€å°æ ·æœ¬æ•°: {min(sizes):,}")
    print(f"    æœ€å¤§æ ·æœ¬æ•°: {max(sizes):,}")
    print(f"    å¹³å‡æ ·æœ¬æ•°: {statistics.mean(sizes):,.0f}")
    print(f"    æ ‡å‡†å·®: {statistics.stdev(sizes):,.0f}")
    print(f"    å·®å¼‚å€æ•°: {max(sizes)/min(sizes):.2f}x")

    if max(sizes) / min(sizes) < 1.1:
        print("  âœ… æ–‡ä»¶å¤§å°éå¸¸å‡åŒ€ï¼")
    else:
        print("  âš ï¸  ä»æœ‰ä¸€äº›å¤§å°å·®å¼‚")
EOF
else
    echo "âŒ é¢„å¤„ç†å¤±è´¥ï¼Œé€€å‡ºç : $EXIT_CODE"
    echo "è¯·æŸ¥çœ‹æ—¥å¿—æ’æŸ¥é—®é¢˜"
    exit $EXIT_CODE
fi

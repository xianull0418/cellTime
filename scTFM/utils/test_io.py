import os
import time
import shutil
import tempfile

def benchmark_io(base_path, size_mb=512, small_file_count=1000):
    """
    æµ‹è¯•æŒ‡å®šè·¯å¾„çš„ IO æ€§èƒ½
    :param base_path: æµ‹è¯•ç›®å½•
    :param size_mb: å¤§æ–‡ä»¶æµ‹è¯•çš„å¤§å° (MB)
    :param small_file_count: å°æ–‡ä»¶æµ‹è¯•çš„æ•°é‡ (æ¨¡æ‹Ÿç¢ç‰‡)
    """
    if not os.path.exists(base_path):
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {base_path}")
        return

    print(f"\n{'='*60}")
    print(f"ğŸš€ æ­£åœ¨æµ‹è¯•è·¯å¾„: {base_path}")
    print(f"{'='*60}")

    # åˆ›å»ºä¸´æ—¶æµ‹è¯•ç›®å½•
    test_dir = os.path.join(base_path, "io_benchmark_temp")
    if os.path.exists(test_dir):
        shutil.rmtree(test_dir)
    os.makedirs(test_dir)

    try:
        # -------------------------------------------------
        # 1. å¤§æ–‡ä»¶é¡ºåºå†™å…¥æµ‹è¯• (Throughput)
        # -------------------------------------------------
        large_file = os.path.join(test_dir, "large_test.dat")
        data_chunk = os.urandom(1024 * 1024) # 1MB chunk
        
        print(f"ğŸ“¦ [1/3] æµ‹è¯•å¤§æ–‡ä»¶å†™å…¥ ({size_mb} MB)...")
        start_time = time.time()
        with open(large_file, 'wb') as f:
            for _ in range(size_mb):
                f.write(data_chunk)
            # å¼ºåˆ¶åˆ·ç›˜ï¼Œç¡®ä¿ä¸åªæ˜¯å†™åˆ°äº†å†…å­˜ Cache é‡Œ
            os.fsync(f.fileno())
        
        write_time = time.time() - start_time
        write_speed = size_mb / write_time
        print(f"   âœ… å†™å…¥é€Ÿåº¦: {write_speed:.2f} MB/s (è€—æ—¶: {write_time:.2f}s)")

        # -------------------------------------------------
        # 2. å¤§æ–‡ä»¶é¡ºåºè¯»å–æµ‹è¯• (Read Throughput)
        # -------------------------------------------------
        print(f"ğŸ“– [2/3] æµ‹è¯•å¤§æ–‡ä»¶è¯»å–...")
        # æ¸…é™¤ç³»ç»Ÿç¼“å­˜ (å°è¯•) - æ™®é€šç”¨æˆ·æƒé™å¯èƒ½æ— æ•ˆï¼Œæ‰€ä»¥è¿™é‡Œä¸»è¦æµ‹è¯»å–åå
        start_time = time.time()
        with open(large_file, 'rb') as f:
            while f.read(1024 * 1024):
                pass
        
        read_time = time.time() - start_time
        read_speed = size_mb / read_time
        print(f"   âœ… è¯»å–é€Ÿåº¦: {read_speed:.2f} MB/s (è€—æ—¶: {read_time:.2f}s)")

        # -------------------------------------------------
        # 3. å°æ–‡ä»¶å¯†é›†å†™å…¥æµ‹è¯• (IOPS / Metadata)
        # -------------------------------------------------
        # TileDB ä¼šäº§ç”Ÿå¤§é‡å°æ–‡ä»¶ï¼Œè¿™ä¸€æ­¥æœ€å…³é”®
        print(f"ğŸ”¨ [3/3] æµ‹è¯•å°æ–‡ä»¶å¯†é›†åˆ›å»º ({small_file_count} files)...")
        small_data = b'x' * 4096 # 4KB data
        
        start_time = time.time()
        for i in range(small_file_count):
            fname = os.path.join(test_dir, f"small_{i}.dat")
            with open(fname, 'wb') as f:
                f.write(small_data)
                # å°æ–‡ä»¶é€šå¸¸ä¾èµ– OS ç¼“å­˜ï¼Œè¿™é‡Œä¸å¼ºåˆ¶ fsync ä»¥æ¨¡æ‹ŸçœŸå®åº”ç”¨è¡Œä¸º
        
        small_time = time.time() - start_time
        iops = small_file_count / small_time
        print(f"   âœ… åˆ›å»ºé€Ÿåº¦: {iops:.2f} files/s (è€—æ—¶: {small_time:.2f}s)")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
    finally:
        # æ¸…ç†
        print(f"ğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
        shutil.rmtree(test_dir)
        print("Done.")

if __name__ == "__main__":
    # ä½ å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ä½ æƒ³æµ‹è¯•çš„ç›®å½•
    paths_to_test = [
        # 1. ä½ çš„æ··åˆç›˜ (ä¹‹å‰å¾ˆæ…¢çš„é‚£ä¸ª)
        "/gpfs/hybrid/data/jcw", 
        
        # 2. ä½ çš„é—ªå­˜ç›˜ (å¸Œæœ›èƒ½æ•‘å‘½çš„é‚£ä¸ª)
        # è¯·æ ¹æ®ä½ çš„ df -h ç»“æœï¼Œç¡®è®¤ä½ æœ‰æƒé™å†™å…¥ flash ç›˜çš„å“ªä¸ªç›®å½•
        # è¿™é‡Œå‡è®¾æ˜¯ä½ çš„ home ç›®å½•æˆ–è€…ä½ æœ‰æƒé™çš„ç›®å½•
        "/gpfs/flash/home/jcw", 
        
        # 3. (å¯é€‰) å¦‚æœä½ æœ‰æœ¬åœ°ç›˜æƒé™ï¼Œä¹Ÿå¯ä»¥æµ‹æµ‹ /tmp
        # "/tmp" 
    ]

    print("å¼€å§‹ IO æ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
    for p in paths_to_test:
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å¯å†™
        if os.access(p, os.W_OK):
            benchmark_io(p, size_mb=512, small_file_count=2000)
        else:
            print(f"\nâŒ è·³è¿‡: {p} (è·¯å¾„ä¸å­˜åœ¨æˆ–æ— å†™å…¥æƒé™)")
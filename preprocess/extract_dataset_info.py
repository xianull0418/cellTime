import argparse
import re
import pandas as pd
from pathlib import Path

def parse_h5ad_log(log_file):
    """è§£æh5adæ—¥å¿—æ–‡ä»¶ï¼Œæå–æ•°æ®é›†ä¿¡æ¯"""
    datasets = {}
    current_dataset = None
    
    with open(log_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # æ£€æµ‹æ–°çš„æ•°æ®é›†å¼€å§‹
        if line.startswith('ğŸ“„ æ­£åœ¨è¯»å–æ–‡ä»¶:'):
            filename = line.replace('ğŸ“„ æ­£åœ¨è¯»å–æ–‡ä»¶:', '').strip()
            dataset_id = filename.replace('.link.h5ad', '')
            current_dataset = {
                'æ•°æ®å': filename,
                'ç»†èƒæ•°ç›®': None,
                'ç‰©ç§': None,
                'ç»„ç»‡': None,
                'æµ‹åºæŠ€æœ¯': None,
                'æ—¶åºå€¼': None,
                'æ—¶åºå•ä½': None
            }
            datasets[dataset_id] = current_dataset
        
        # æå–ç»†èƒæ•°é‡
        elif current_dataset and 'ç»†èƒæ•°é‡ (obs):' in line:
            match = re.search(r'ç»†èƒæ•°é‡ \(obs\): ([0-9,]+)', line)
            if match:
                current_dataset['ç»†èƒæ•°ç›®'] = match.group(1).replace(',', '')
        
        # æå–éç»“æ„åŒ–æ•°æ®
        elif current_dataset and line.startswith('éç»“æ„åŒ–æ•°æ® (uns):'):
            i += 1
            while i < len(lines) and not lines[i].startswith('ğŸ“„') and not lines[i].startswith('==='):
                uns_line = lines[i].strip()
                if 'Species: str =' in uns_line:
                    current_dataset['ç‰©ç§'] = uns_line.split('= ')[1] if '= ' in uns_line else uns_line.split('=')[1]
                elif 'Tissue: str =' in uns_line:
                    current_dataset['ç»„ç»‡'] = uns_line.split('= ')[1] if '= ' in uns_line else uns_line.split('=')[1]
                elif 'Technology: str =' in uns_line:
                    current_dataset['æµ‹åºæŠ€æœ¯'] = uns_line.split('= ')[1] if '= ' in uns_line else uns_line.split('=')[1]
                elif 'timepoints: str =' in uns_line:
                    current_dataset['æ—¶åºå€¼'] = uns_line.split('= ')[1] if '= ' in uns_line else uns_line.split('=')[1]
                elif 'time_unit: str =' in uns_line:
                    current_dataset['æ—¶åºå•ä½'] = uns_line.split('= ')[1] if '= ' in uns_line else uns_line.split('=')[1]
                i += 1
            continue
        
        i += 1
    
    return datasets

def parse_csv_table(csv_file):
    """è§£æCSVè¡¨æ ¼æ–‡ä»¶"""
    df = pd.read_csv(csv_file)
    # æ¸…ç†æ•°æ®ï¼Œç§»é™¤ç©ºè¡Œ
    df = df.dropna(how='all')
    
    datasets = {}
    for _, row in df.iterrows():
        dataset_id = row['ID']
        datasets[dataset_id] = {
            'ç‰©ç§': row['Species'],
            'ç»„ç»‡': row['Tissue'],
            'æµ‹åºæŠ€æœ¯': row['Sequencing'],
            'æ—¶åºå€¼': row['sorted_time'],
            'æ—¶åºå•ä½': row['time_unit'],
            'Cell': row['Cell']
        }
    return datasets

def main():
    parser = argparse.ArgumentParser(description='æå–å•ç»†èƒæ•°æ®é›†ä¿¡æ¯')
    parser.add_argument('log_file', help='view_h5ad.log.txtæ–‡ä»¶è·¯å¾„')
    parser.add_argument('csv_file', help='tedd_datasets_table_processed.csvæ–‡ä»¶è·¯å¾„')
    parser.add_argument('storage_path', help='æ•°æ®å­˜å‚¨è·¯å¾„')
    parser.add_argument('data_source', help='æ•°æ®æ¥æº', default='TEDD')
    
    args = parser.parse_args()
    
    # è§£ææ–‡ä»¶
    log_datasets = parse_h5ad_log(args.log_file)
    csv_datasets = parse_csv_table(args.csv_file)
    
    # åˆå¹¶æ•°æ®ï¼Œä¼˜å…ˆä½¿ç”¨CSVä¸­çš„æ•°æ®
    results = []
    
    for dataset_id, log_info in log_datasets.items():
        result = {
            'æ•°æ®å': log_info['æ•°æ®å'],
            'å­˜å‚¨è·¯å¾„': args.storage_path,
            'æ•°æ®ç±»å‹': 'h5ad',
            'æ•°æ®æ¥æº': args.data_source,
            'æ•°æ®ç”¨é€”': 'å•ç»†èƒè½¬å½•ç»„åˆ†æ',
            'å­˜å‚¨æ ¼å¼': 'h5ad',
            'ç»†èƒæ•°ç›®': log_info['ç»†èƒæ•°ç›®'],
            'ç‰©ç§': None,
            'ç»„ç»‡': None,
            'æµ‹åºæŠ€æœ¯': None,
            'å¥åº·/ç–¾ç—…': 'å¥åº·',  # é»˜è®¤ä¸ºå¥åº·ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´
            'æ˜¯å¦æ‰°åŠ¨': 'å¦',     # é»˜è®¤ä¸ºå¦ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´
            'æ‰°åŠ¨ç±»å‹': '',
            'æ‰°åŠ¨æ•°': '0',
            'æ˜¯å¦å«æ—¶åºä¿¡æ¯': 'æ˜¯',
            'é‡‡æ ·ç‚¹æ•°ç›®': None,
            'æ—¶åºå€¼': None,
            'æ—¶åºå•ä½': None
        }
        
        # ä¼˜å…ˆä½¿ç”¨CSVä¸­çš„æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨logä¸­çš„æ•°æ®
        if dataset_id in csv_datasets:
            csv_info = csv_datasets[dataset_id]
            result['ç‰©ç§'] = csv_info['ç‰©ç§']
            result['ç»„ç»‡'] = csv_info['ç»„ç»‡']
            result['æµ‹åºæŠ€æœ¯'] = csv_info['æµ‹åºæŠ€æœ¯']
            result['æ—¶åºå€¼'] = csv_info['æ—¶åºå€¼']
            result['æ—¶åºå•ä½'] = csv_info['æ—¶åºå•ä½']
            # å¦‚æœlogä¸­æ²¡æœ‰ç»†èƒæ•°ç›®ï¼Œå°è¯•ä½¿ç”¨CSVä¸­çš„Cellåˆ—
            if not result['ç»†èƒæ•°ç›®'] and 'Cell' in csv_info:
                result['ç»†èƒæ•°ç›®'] = str(csv_info['Cell'])
        else:
            # ä½¿ç”¨logä¸­çš„æ•°æ®
            result['ç‰©ç§'] = log_info['ç‰©ç§']
            result['ç»„ç»‡'] = log_info['ç»„ç»‡']
            result['æµ‹åºæŠ€æœ¯'] = log_info['æµ‹åºæŠ€æœ¯']
            result['æ—¶åºå€¼'] = log_info['æ—¶åºå€¼']
            result['æ—¶åºå•ä½'] = log_info['æ—¶åºå•ä½']
        
        # è®¡ç®—é‡‡æ ·ç‚¹æ•°ç›®
        if result['æ—¶åºå€¼']:
            timepoints = str(result['æ—¶åºå€¼']).split(',')
            result['é‡‡æ ·ç‚¹æ•°ç›®'] = str(len(timepoints))
        
        # å¦‚æœæ²¡æœ‰æ—¶åºä¿¡æ¯ï¼Œåˆ™æ›´æ–°ç›¸å…³å­—æ®µ
        if not result['æ—¶åºå€¼']:
            result['æ˜¯å¦å«æ—¶åºä¿¡æ¯'] = 'å¦'
            result['é‡‡æ ·ç‚¹æ•°ç›®'] = '0'
            result['æ—¶åºå€¼'] = ''
            result['æ—¶åºå•ä½'] = ''
        
        results.append(result)
    
    # åˆ›å»ºç»“æœDataFrame
    df_output = pd.DataFrame(results)
    
    # é‡æ–°æ’åˆ—åˆ—é¡ºåº
    columns_order = [
        'æ•°æ®å', 'å­˜å‚¨è·¯å¾„', 'æ•°æ®ç±»å‹', 'æ•°æ®æ¥æº', 'æ•°æ®ç”¨é€”', 'å­˜å‚¨æ ¼å¼',
        'ç»†èƒæ•°ç›®', 'ç‰©ç§', 'ç»„ç»‡', 'æµ‹åºæŠ€æœ¯', 'å¥åº·/ç–¾ç—…', 'æ˜¯å¦æ‰°åŠ¨',
        'æ‰°åŠ¨ç±»å‹', 'æ‰°åŠ¨æ•°', 'æ˜¯å¦å«æ—¶åºä¿¡æ¯', 'é‡‡æ ·ç‚¹æ•°ç›®', 'æ—¶åºå€¼', 'æ—¶åºå•ä½'
    ]
    df_output = df_output[columns_order]
    
    # ä¿å­˜ç»“æœ
    output_file = 'dataset_info_summary.csv'
    df_output.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    
    # æ‰“å°å‰å‡ è¡Œé¢„è§ˆ
    print("\nå‰5è¡Œæ•°æ®é¢„è§ˆ:")
    print(df_output.head().to_string(index=False))

if __name__ == '__main__':
    main()
